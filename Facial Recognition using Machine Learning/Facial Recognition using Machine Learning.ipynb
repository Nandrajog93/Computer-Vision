{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Facial Recognition using Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Training Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'face_classifier = cv2.CascadeClassifier(\\'/Users/nandrajog/haarcascade_frontalface_default.xml\\')\\ndef face_detector(image):\\n    \\n    grey_scale = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\\n    faces = face_classifier.detectMultiScale(grey_scale, 1.5,4)\\n    \\n    \\n    if faces is ():\\n        return None\\n    \\n    #Crop all the faces found\\n    \\n    for (x,y,w,h) in faces:\\n        cropped_faces = image[y:y+h, x:x+w]\\n    return cropped_faces\\n\\n#Initialize the web cam\\n\\ncap = cv2.VideoCapture(0)\\ncount = 0\\n\\n#Collect  100 sample of you faces\\n\\nwhile True:\\n    _,frame = cap.read()\\n    if face_detector(frame) is not None:\\n        count+= 1\\n        face = cv2.resize(face_detector(frame),(200,200))\\n        face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\\n        \\n        \\n        #Save the file in specified DIRECTORY with unique name\\n        \\n        path = (\\'/Users/nandrajog/Face_Recognition\\' +str(count) + \\'.jpg\\')\\n        cv2.imwrite(path,face)\\n        \\n        #Put count on images and display live count\\n        \\n        cv2.putText(face,str(count),(50,50), cv2.FONT_HERSHEY_COMPLEX,1,(0,0,127),3)\\n        cv2.imshow(\"face cropper\",face) \\n        \\n    else:\\n        print(\"face not found\")\\n        pass\\n        \\n    if cv2.waitKey(1)==13 or count == 100:\\n        break\\n            \\ncap.release()\\ncv2.destroyAllWindows()\\n\\nprint(\"collecting samples complete\")'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''face_classifier = cv2.CascadeClassifier('/Users/nandrajog/haarcascade_frontalface_default.xml')\n",
    "def face_detector(image):\n",
    "    \n",
    "    grey_scale = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(grey_scale, 1.5,4)\n",
    "    \n",
    "    \n",
    "    if faces is ():\n",
    "        return None\n",
    "    \n",
    "    #Crop all the faces found\n",
    "    \n",
    "    for (x,y,w,h) in faces:\n",
    "        cropped_faces = image[y:y+h, x:x+w]\n",
    "    return cropped_faces\n",
    "\n",
    "#Initialize the web cam\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "count = 0\n",
    "\n",
    "#Collect  100 sample of you faces\n",
    "\n",
    "while True:\n",
    "    _,frame = cap.read()\n",
    "    if face_detector(frame) is not None:\n",
    "        count+= 1\n",
    "        face = cv2.resize(face_detector(frame),(200,200))\n",
    "        face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        \n",
    "        #Save the file in specified DIRECTORY with unique name\n",
    "        \n",
    "        path = ('/Users/nandrajog/Face_Recognition' +str(count) + '.jpg')\n",
    "        cv2.imwrite(path,face)\n",
    "        \n",
    "        #Put count on images and display live count\n",
    "        \n",
    "        cv2.putText(face,str(count),(50,50), cv2.FONT_HERSHEY_COMPLEX,1,(0,0,127),3)\n",
    "        cv2.imshow(\"face cropper\",face) \n",
    "        \n",
    "    else:\n",
    "        print(\"face not found\")\n",
    "        pass\n",
    "        \n",
    "    if cv2.waitKey(1)==13 or count == 100:\n",
    "        break\n",
    "            \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(\"collecting samples complete\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_detector = cv2.CascadeClassifier('/Users/nandrajog/haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "collecting Samples complete\n"
     ]
    }
   ],
   "source": [
    "def face_classifier(image):\n",
    "    \n",
    "    grey_scale = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "    face = face_detector.detectMultiScale(grey_scale,1.2,3)\n",
    "    \n",
    "    if face is ():\n",
    "        return None\n",
    "    \n",
    "    \n",
    "    #cropped image\n",
    "    \n",
    "    for (x,y,w,h) in face:\n",
    "        cropped_image = image[y:y+h,x:x+w, ]\n",
    "    return cropped_image\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "count = 0 \n",
    "\n",
    "while True:\n",
    "    \n",
    "    _, frame = cap.read()\n",
    "    \n",
    "    if face_classifier(frame) is not None:\n",
    "        count += 1\n",
    "        \n",
    "        faces = cv2.resize(face_classifier(frame),(300,300))\n",
    "        faces = cv2.cvtColor(faces,cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        #SAVE FILE IN SPCIFIC FOLDER AND DIRECTORT \n",
    "        \n",
    "        path = ('/Users/nandrajog/Face_Recognition/' + str(count) +'.jpg')\n",
    "        cv2.imwrite(path,faces)\n",
    "        \n",
    "        #Put count on the image\n",
    "        \n",
    "        cv2.putText(faces,str(count),(150,150),cv2.FONT_HERSHEY_COMPLEX,1,(0,127,127),3)\n",
    "        cv2.imshow('face_cropper', faces)\n",
    "        \n",
    "    else:\n",
    "        print(\"face not found\")\n",
    "        pass\n",
    "    \n",
    "    if cv2.waitKey(1)== 13 or count == 100:\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "print('collecting Samples complete')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile ,join\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the training data\n",
    "data_path = ('/Users/nandrajog/Face_Recognition/')\n",
    "onlyfile = [i for i in  listdir(data_path) if isfile(join(data_path,i))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['63.jpg',\n",
       " '77.jpg',\n",
       " '88.jpg',\n",
       " '89.jpg',\n",
       " '76.jpg',\n",
       " '62.jpg',\n",
       " '74.jpg',\n",
       " '60.jpg',\n",
       " '48.jpg',\n",
       " '49.jpg',\n",
       " '61.jpg',\n",
       " '75.jpg',\n",
       " '59.jpg',\n",
       " '71.jpg',\n",
       " '65.jpg',\n",
       " '64.jpg',\n",
       " '70.jpg',\n",
       " '58.jpg',\n",
       " '8.jpg',\n",
       " '66.jpg',\n",
       " '72.jpg',\n",
       " '99.jpg',\n",
       " '98.jpg',\n",
       " '73.jpg',\n",
       " '67.jpg',\n",
       " '9.jpg',\n",
       " '14.jpg',\n",
       " '28.jpg',\n",
       " '100.jpg',\n",
       " '29.jpg',\n",
       " '15.jpg',\n",
       " '17.jpg',\n",
       " '16.jpg',\n",
       " '12.jpg',\n",
       " '13.jpg',\n",
       " '39.jpg',\n",
       " '11.jpg',\n",
       " '10.jpg',\n",
       " '38.jpg',\n",
       " '21.jpg',\n",
       " '35.jpg',\n",
       " '34.jpg',\n",
       " '20.jpg',\n",
       " '36.jpg',\n",
       " '22.jpg',\n",
       " '23.jpg',\n",
       " '37.jpg',\n",
       " '33.jpg',\n",
       " '27.jpg',\n",
       " '26.jpg',\n",
       " '32.jpg',\n",
       " '18.jpg',\n",
       " '24.jpg',\n",
       " '30.jpg',\n",
       " '31.jpg',\n",
       " '25.jpg',\n",
       " '19.jpg',\n",
       " '42.jpg',\n",
       " '4.jpg',\n",
       " '56.jpg',\n",
       " '81.jpg',\n",
       " '95.jpg',\n",
       " '94.jpg',\n",
       " '80.jpg',\n",
       " '5.jpg',\n",
       " '57.jpg',\n",
       " '43.jpg',\n",
       " '55.jpg',\n",
       " '7.jpg',\n",
       " '41.jpg',\n",
       " '69.jpg',\n",
       " '96.jpg',\n",
       " '82.jpg',\n",
       " '83.jpg',\n",
       " '97.jpg',\n",
       " '68.jpg',\n",
       " '40.jpg',\n",
       " '54.jpg',\n",
       " '6.jpg',\n",
       " '78.jpg',\n",
       " '2.jpg',\n",
       " '50.jpg',\n",
       " '44.jpg',\n",
       " '93.jpg',\n",
       " '87.jpg',\n",
       " '86.jpg',\n",
       " '92.jpg',\n",
       " '45.jpg',\n",
       " '3.jpg',\n",
       " '51.jpg',\n",
       " '79.jpg',\n",
       " '47.jpg',\n",
       " '53.jpg',\n",
       " '1.jpg',\n",
       " '84.jpg',\n",
       " '90.jpg',\n",
       " '91.jpg',\n",
       " '85.jpg',\n",
       " '52.jpg',\n",
       " '46.jpg']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onlyfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create arrays for training data and labels\n",
    "\n",
    "Training_data = []\n",
    "label = [] \n",
    "\n",
    "#Open training images in our datapath\n",
    "#Create a numpy array for trainning data\n",
    "\n",
    "for j , files in enumerate (onlyfile):\n",
    "    image_path = data_path + onlyfile[j]\n",
    "    images = cv2.imread(image_path,cv2.IMREAD_GRAYSCALE)\n",
    "    Training_data.append(np.asarray(images ,dtype = np.uint8))\n",
    "    label.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/nandrajog/Face_Recognition/46.jpg'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a numpy array for trainning data and labels\n",
    "\n",
    "label= np.asarray(label,np.int32)\n",
    "\n",
    "#Intialize the facial recognizer\n",
    "model = cv2.face.LBPHFaceRecognizer_create()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model trained\n"
     ]
    }
   ],
   "source": [
    "#Let's train our model \n",
    "model.train(np.asarray(Training_data), np.asarray(label))\n",
    "print('model trained')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RUN our Facial Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_Recognition = cv2.CascadeClassifier('/Users/nandrajog/haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_detect(image,size = 0.5):\n",
    "    grey = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "    face = face_Recognition.detectMultiScale(grey,1.3,5)\n",
    "    \n",
    "    if face is ():\n",
    "        return image,[]\n",
    "    \n",
    "    for(x,y,w,h) in face:\n",
    "        cv2.rectangle(image,(x,y),(x+w , y+h),(0,0,127),3)\n",
    "        roi = image[y: y+h , x: x+w]\n",
    "        roi = cv2.resize(roi , (200,200))\n",
    "    return image , roi\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    _,frame = cap.read()\n",
    "    image ,face = face_detect(frame)\n",
    "    \n",
    "    try:\n",
    "        face = cv2.cvtColor(face,cv2.COLOR_BGR2GRAY)\n",
    "        result = model.predict(face)\n",
    "        \n",
    "        if result[1] < 500:\n",
    "            confidence     = int(100*(1-(result[1])/300))\n",
    "            display_string = str(confidence) + \"% confident it is a user \"\n",
    "            \n",
    "        cv2.putText(image,display_string,(100,120),cv2.FONT_HERSHEY_COMPLEX, 1,(100,255,150),2)\n",
    "        \n",
    "        \n",
    "        \n",
    "        if confidence > 80:\n",
    "            cv2.putText(image,\"Unlocked\",(250,450),cv2.FONT_HERSHEY_COMPLEX, 1,(0,255,0),2)\n",
    "            cv2.show(\"face cropper\" , image) \n",
    "            \n",
    "        else:\n",
    "            cv2.putText(image,\"locked\",(250,450),cv2.FONT_HERSHEY_COMPLEX, 1,(0,255,0),2)\n",
    "            cv2.show(\"face cropper\" , image)\n",
    "            \n",
    "    except:\n",
    "        cv2.putText(image,\"No face found\",(220,120),cv2.FONT_HERSHEY_COMPLEX, 1,(0,0,116),3)\n",
    "        cv2.putText(image,\"locked\",(250,420),cv2.FONT_HERSHEY_COMPLEX, 1,(0,0,116),3)\n",
    "        cv2.imshow('face cropper', image)\n",
    "        pass\n",
    "    \n",
    "    if cv2.waitKey(1) == 13:\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "        \n",
    "            \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
