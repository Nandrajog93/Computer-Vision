{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Detection Using ORB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will use ORB because SFIT is patent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descriptor --> Are vector that store information about keypoints they are very important this is how we do matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we define a function called ORB_detector that compare input image to template\n",
    "#This Function return number of ORB matches between them \n",
    "def ORB_detector(new_image,template_image):\n",
    "    \n",
    "    image1= cv2.cvtColor(new_image,cv2.COLOR_BGR2GRAY)\n",
    "    image2 = template_image\n",
    "    \n",
    "    #Create ORB detector\n",
    "    \n",
    "    ORB = cv2.ORB_create()\n",
    "    \n",
    "    #Detect the keypoints of image1 & image2\n",
    "    keypoints1 = ORB.detect(image1,None)\n",
    "    keypoints2 = ORB.detect(image2,None)\n",
    "    \n",
    "    # compute the descriptors with ORB of image1 & image2\n",
    "    \n",
    "    \n",
    "#Descriptor --> Are vector that store information about keypoints they are very important this is how we do matching\n",
    "    _,descriptors1 = ORB.compute(image1,keypoints1)\n",
    "    _,descriptors2 = ORB.compute(image2,keypoints2)\n",
    "    \n",
    "    \n",
    "    #Lets CREATE A MATCHER\n",
    "    #Here we are using BFmatcher\n",
    "    bf = cv2.BFMatcher(cv2.NORM_HAMMING,crossCheck = True) #Here we make crossCheck =True for better result\n",
    "    \n",
    "    #Do matching\n",
    "    matches = bf.match(descriptors1,descriptors2)\n",
    "    \n",
    "    #Sort the matches based on distance\n",
    "    #Least Distance is Better\n",
    "    \n",
    "    matches = sorted(matches,key=lambda val: val.distance)\n",
    "    \n",
    "    return len(matches)\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "#Load our image template\n",
    "template_image = cv2.imread('/Users/nandrajog/BB.JPG',0)\n",
    "\n",
    "#Lets paly with webcam:\n",
    "\n",
    "while True:\n",
    "    #Get webcam images\n",
    "    _, frame = cap.read()\n",
    "    \n",
    "    #Here we are creating Height and width of webcam frame\n",
    "    Height  ,width  = frame.shape[:2]\n",
    "    \n",
    "    #Define ROI of Box Dimension\n",
    "    top_left_x = int(width /3 )\n",
    "    top_left_y = int((Height / 2) + (Height / 4))\n",
    "    \n",
    "    bottom_right_x = int((width / 3) *2)\n",
    "    bottom_right_y = int((Height /2 ) - (Height / 4))\n",
    "    \n",
    "    \n",
    "    #Draw Rectangle\n",
    "    cv2.rectangle(frame, (top_left_x,top_left_y),(bottom_right_x,bottom_right_y), 255,3)\n",
    "    #cv2.rectangle(frame, ((width/3),(Height/2) + (Height/4)),((width/3)*2,(Height/2) - (Height/4)), 255,2)\n",
    "    \n",
    "    \n",
    "    #Cropped the window\n",
    "    cropped = frame[bottom_right_y:top_left_y , top_left_x : bottom_right_x:]\n",
    "    \n",
    "    #Flip frame orientation horizontally\n",
    "    \n",
    "    frame = cv2.flip(frame,1)\n",
    "    \n",
    "    \n",
    "    #Get number of ORB matches\n",
    "    \n",
    "    matches =ORB_detector(cropped,template_image)\n",
    "    \n",
    "    #We will put the text in the frame\n",
    "    output_text = \"Matches = \" + str(matches)\n",
    "    cv2.putText(frame,output_text,(50,450),cv2.FONT_HERSHEY_COMPLEX,2,(0,0,255),2)\n",
    "    \n",
    "    #Now we will define out Threshold\n",
    "    Threshold = 175\n",
    "    \n",
    "    #If matches exceed our threshold then object has been detected\n",
    "    \n",
    "    if matches >Threshold:\n",
    "        cv2.rectangle(frame,(top_left_x,top_left_y),(bottom_right_x,bottom_right_y),255,3)\n",
    "        cv2.putText(frame,\"Object Found\",(50,50),cv2.FONT_HERSHEY_SIMPLEX,2,(0,255,0),2)\n",
    "        \n",
    "    cv2.imshow(\"Object Detector using ORB\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) == 13:\n",
    "        break\n",
    "        \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "    \n",
    "    \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
